{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "604d5751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\dnjsd\\anaconda3\\envs\\torch\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: nltk in c:\\users\\dnjsd\\anaconda3\\envs\\torch\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\dnjsd\\anaconda3\\envs\\torch\\lib\\site-packages (0.2.0)\n",
      "Requirement already satisfied: einops in c:\\users\\dnjsd\\anaconda3\\envs\\torch\\lib\\site-packages (0.8.1)\n",
      "Requirement already satisfied: wandb in c:\\users\\dnjsd\\anaconda3\\envs\\torch\\lib\\site-packages (0.21.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\dnjsd\\anaconda3\\envs\\torch\\lib\\site-packages (1.5.1)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.7.0-cp310-cp310-win_amd64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\dnjsd\\anaconda3\\envs\\torch\\lib\\site-packages (from pandas) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\dnjsd\\anaconda3\\envs\\torch\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dnjsd\\anaconda3\\envs\\torch\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\dnjsd\\anaconda3\\envs\\torch\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: click in c:\\users\\dnjsd\\anaconda3\\envs\\torch\\lib\\site-packages (from nltk) (8.2.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\dnjsd\\anaconda3\\envs\\torch\\lib\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\dnjsd\\anaconda3\\envs\\torch\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in c:\\users\\dnjsd\\anaconda3\\envs\\torch\\lib\\site-packages (from wandb) (3.1.44)\n",
      "Requirement already satisfied: packaging in c:\\users\\dnjsd\\anaconda3\\envs\\torch\\lib\\site-packages (from wandb) (25.0)\n",
      "Requirement already satisfied: platformdirs in c:\\users\\dnjsd\\anaconda3\\envs\\torch\\lib\\site-packages (from wandb) (4.3.8)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in c:\\users\\dnjsd\\anaconda3\\envs\\torch\\lib\\site-packages (from wandb) (6.31.1)\n",
      "Requirement already satisfied: pydantic<3 in c:\\users\\dnjsd\\anaconda3\\envs\\torch\\lib\\site-packages (from wandb) (2.11.7)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\dnjsd\\anaconda3\\envs\\torch\\lib\\site-packages (from wandb) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in c:\\users\\dnjsd\\anaconda3\\envs\\torch\\lib\\site-packages (from wandb) (2.32.4)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in c:\\users\\dnjsd\\anaconda3\\envs\\torch\\lib\\site-packages (from wandb) (2.32.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.8 in c:\\users\\dnjsd\\anaconda3\\envs\\torch\\lib\\site-packages (from wandb) (4.14.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\dnjsd\\anaconda3\\envs\\torch\\lib\\site-packages (from pydantic<3->wandb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\dnjsd\\anaconda3\\envs\\torch\\lib\\site-packages (from pydantic<3->wandb) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\dnjsd\\anaconda3\\envs\\torch\\lib\\site-packages (from pydantic<3->wandb) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\dnjsd\\anaconda3\\envs\\torch\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dnjsd\\anaconda3\\envs\\torch\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dnjsd\\anaconda3\\envs\\torch\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dnjsd\\anaconda3\\envs\\torch\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2025.7.9)\n",
      "Collecting scipy>=1.8.0 (from scikit-learn)\n",
      "  Using cached scipy-1.15.3-cp310-cp310-win_amd64.whl.metadata (60 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\dnjsd\\anaconda3\\envs\\torch\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\dnjsd\\anaconda3\\envs\\torch\\lib\\site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\dnjsd\\anaconda3\\envs\\torch\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dnjsd\\anaconda3\\envs\\torch\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading scikit_learn-1.7.0-cp310-cp310-win_amd64.whl (10.7 MB)\n",
      "   ---------------------------------------- 0.0/10.7 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.8/10.7 MB 5.6 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 1.3/10.7 MB 6.1 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.6/10.7 MB 2.7 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 2.4/10.7 MB 3.1 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 3.7/10.7 MB 3.9 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 5.2/10.7 MB 4.5 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 6.8/10.7 MB 5.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 8.7/10.7 MB 5.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.7/10.7 MB 6.1 MB/s eta 0:00:00\n",
      "Using cached scipy-1.15.3-cp310-cp310-win_amd64.whl (41.3 MB)\n",
      "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, scikit-learn\n",
      "\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   ------------- -------------------------- 1/3 [scipy]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   ---------------------------------------- 3/3 [scikit-learn]\n",
      "\n",
      "Successfully installed scikit-learn-1.7.0 scipy-1.15.3 threadpoolctl-3.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas nltk sentencepiece einops wandb joblib scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cbd16cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from Korpora import Korpora\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "# from konlpy.tag import Mecab\n",
    "from nltk.tokenize import word_tokenize as en_tokenizer\n",
    "import sentencepiece as spm\n",
    "import urllib.request\n",
    "import csv\n",
    "import numpy as np\n",
    "from einops import rearrange, reduce, repeat\n",
    "from torch.cuda import amp\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "import time\n",
    "import copy\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import joblib\n",
    "import gc\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ac04d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeMask(tensor, option: str) -> torch.Tensor:\n",
    "    \n",
    "    if option == 'padding':\n",
    "        tmp = torch.full_like(tensor, fill_value=PAD_IDX).to(device) #(bs, seq_len)\n",
    "        mask = (tensor != tmp).float() #(bs, seq_len)\n",
    "        mask = rearrange(mask, 'bs seq_len -> bs 1 1 seq_len')\n",
    "        \n",
    "    elif option == 'lookahead':\n",
    "        #inQ seq_len == inK seq_len\n",
    "        \n",
    "        padding_mask = makeMask(tensor, 'padding')\n",
    "        padding_mask = np.repeat(padding_mask, 'bs 1 1 k_len -> bs 1 new k_len', new=padding_mask.size[3])\n",
    "        \n",
    "        mask = torch.ones_like(padding_mask)\n",
    "        mask = torch.tril(mask)\n",
    "        \n",
    "        mask = mask * padding_mask\n",
    "        \n",
    "    return mask\n",
    "\n",
    "class PositionWiseFeedForwardNetwork(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super().__init__()\n",
    "        \n",
    "        #d_model = 512\n",
    "        self.d_model = d_model\n",
    "        #d_ff = 2048\n",
    "        self.d_ff = d_ff\n",
    "\n",
    "        self.fc1 = nn.Linear(d_model, d_ff) #512->2048 fc 512 in\n",
    "        self.fc2 = nn.Linear(d_ff, d_model) #2048->512 fc 512 out\n",
    "        #This consists of two linear transformations with a ReLU activation in between.\n",
    "        self.relu = nn.ReLU(inplace=False)\n",
    "        #Refs Residual Dropout -> We apply dropout ... for the base model we use a rate of 0.1\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        output = input\n",
    "        output = self.fc1(output)\n",
    "        output2 = self.relu(output)\n",
    "        output2 = self.dropout(output2)\n",
    "        output3 = self.fc2(output2)\n",
    "        return output3\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model: int, num_head: int):\n",
    "        \n",
    "        # d_model = 512 at paper\n",
    "        self.d_model = d_model\n",
    "        # num_head = 8 at paper\n",
    "        self.num_head = num_head\n",
    "        #dk = dv = d_model // h\n",
    "        self.head_dim = d_model // num_head\n",
    "        self.scale = torch.sqrt(torch.FloatTensor(())).to(device)\n",
    "        \n",
    "        self.fcQ = nn.Linear(d_model, d_model) # Q->Linear\n",
    "        self.fcK = nn.Linear(d_model, d_model) # K->Linear\n",
    "        self.fcV = nn.Linear(d_model, d_model) # V->Linear\n",
    "        self.fcOut = nn.Linear(d_model, d_model)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        #구조는 3.2 Attention Part 참조 Scaled_Dot-Product_Attention(V->Linear, K->Linear, Q->Linear)->Concat->Linear\n",
    "        \n",
    "        \n",
    "    def forward(self, inQ, inK, inV, mask=None):\n",
    "        #Saled Dot Product Attention\n",
    "        \n",
    "        #INPUT\n",
    "        Q = self.fcQ(inQ)\n",
    "        K = self.fcK(inK)\n",
    "        V = self.fcV(inV)\n",
    "        \n",
    "        Q = rearrange(Q, 'bs seq_len (num_head head_dim) -> bs num_head seq_len head_dim', num_head=self.num_head)\n",
    "        K = rearrange(K, 'bs seq_len (num_head head_dim) -> bs num_head seq_len head_dim', num_head=self.num_head)\n",
    "        V = rearrange(V, 'bs seq_len (num_head head_dim) -> bs num_head seq_len head_dim', num_head=self.num_head)\n",
    "        \n",
    "        # Q*K_T / sqrt(dk)\n",
    "        attention_energy = torch.matmul(Q,K.transpose(-2, -1)) / math.sqrt(self.head_dim)\n",
    "        #어텐션 에네르기 계산\n",
    "        #어텐션 에네르기 -> Q와 K가 얼마나 관련있는지 나타내는 raw Score\n",
    "        \n",
    "        #Apply Masking\n",
    "        if mask is not None:\n",
    "            attention_energy = torch.masked_fill(attention_energy, (mask==0), -1e9)\n",
    "            \n",
    "        attention_score = torch.softmax(attention_energy, dim = -1)\n",
    "        \n",
    "        result = torch.matmul(self.dropout(attention_score), V)\n",
    "        \n",
    "        #Concat\n",
    "        result = rearrange(result, 'bs num_head seq_len head_dim -> bs seq_len (num_head head_dim)')\n",
    "        \n",
    "        #Linear\n",
    "        result = self.fcOut(result)\n",
    "        \n",
    "        return result\n",
    "        \n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_head, d_ff):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.num_head = num_head\n",
    "        self.d_ff = d_ff\n",
    "        \n",
    "        self.multi_head_attention = MultiHeadAttention(d_model, num_head)\n",
    "        self.ffn = PositionWiseFeedForwardNetwork(d_model, d_ff)\n",
    "        self.layerNorm1 = nn.LayerNorm(d_model)\n",
    "        self.dropout1 = nn.Dropout(0.1)\n",
    "        self.layerNorm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout2 = nn.Dropout(0.1)\n",
    "        \n",
    "    def forward(self, input, mask=None):\n",
    "        output = self.multi_head_attention(inQ=input, inK=input, inV=input, mask=mask)\n",
    "        output = self.dropout1(output)\n",
    "        output = input + output\n",
    "        output = self.layerNorm1(output)\n",
    "        \n",
    "        output_tmp = self.ffn(output)\n",
    "        output_tmp = self.dropout2(output_tmp)\n",
    "        output = output + output_tmp\n",
    "        output = self.layerNorm2(output)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, N, d_model, num_head, d_ff, max_len=5000):\n",
    "        super().__init__()\n",
    "        \n",
    "        #N=엔코다 레이아 반복 수\n",
    "        self.N = N\n",
    "        self.d_model = d_model\n",
    "        self.num_head = num_head\n",
    "        self.d_ff = d_ff\n",
    "        \n",
    "        self.embedding = nn.Embedding(num_embeddings=VOCAB_SIZE, embedding_dim=d_model, padding_idx=0)\n",
    "        self.pos_embedding = nn.Embedding(max_len, d_model)\n",
    "        self.encoder_layers = nn.ModuleList([EncoderLayer(d_model, num_head, d_ff) for _ in range(N)])\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, input, mask=None):\n",
    "        batch_size = input.shape[0]\n",
    "        seq_len = input.shape[1]\n",
    "        \n",
    "        mask = makeMask(input, 'padding')\n",
    "        \n",
    "        pos = torch.arange(0, seq_len).unsqueeze(0).repeat(batch_size, 1).to(device)\n",
    "        \n",
    "        #임베딩\n",
    "        output = self.dropout(self.embedding(input) + self.pos_embedding(pos))\n",
    "        \n",
    "        output = self.dropout(output)\n",
    "        \n",
    "        for layer in self.encoder_layers:\n",
    "            output = layer(output, mask)\n",
    "            \n",
    "        return output\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_head, d_ff):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.num_head = num_head\n",
    "        self.d_ff = d_ff\n",
    "        \n",
    "        self.multi_head_attention1 = MultiHeadAttention(d_model, num_head)\n",
    "        self.layerNorm1 = nn.LayerNorm(d_model)\n",
    "        self.dropout1 = nn.Dropout(0.1)\n",
    "        \n",
    "        self.multi_head_attention2 = MultiHeadAttention(d_model, num_head)\n",
    "        self.layerNorm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout2 = nn.Dropout(0.1)\n",
    "        \n",
    "        self.ffn = PositionWiseFeedForwardNetwork(d_model, d_ff)\n",
    "        self.layerNorm3 = nn.LayerNorm(d_model)\n",
    "        self.dropout3 = nn.Dropout(0.1)\n",
    "        \n",
    "    def forward(self, input, enc_output, paddingMask, lookahedMask):\n",
    "        \n",
    "        #1\n",
    "        output = self.multi_head_attention1(input, input, input, lookahedMask)\n",
    "        output = self.dropout1(output)\n",
    "        output = output + input\n",
    "        output = self.layerNorm1(output)\n",
    "        \n",
    "        output_tmp = self.multi_head_attention2(output, enc_output, enc_output, paddingMask)\n",
    "        output_tmp = self.dropout2(output_tmp)\n",
    "        output = output + output_tmp\n",
    "        output = self.layerNorm2(output)\n",
    "        \n",
    "        output_tmp = self.ffn(output)\n",
    "        output_tmp = self.dropout3(output_tmp)\n",
    "        output = output + output_tmp\n",
    "        output = self.layerNorm3(output)\n",
    "        \n",
    "        return output\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, N, d_model, num_head, d_ff, max_len=5000):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.N = N\n",
    "        self.d_model = d_model\n",
    "        self.num_head = num_head\n",
    "        self.d_ff = d_ff\n",
    "        \n",
    "        self.embedding = nn.Embedding(num_embeddings=VOCAB_SIZE, embedding_dim=d_model, padding_idx=0)\n",
    "        self.pos_embedding = nn.Embedding(max_len, d_model)\n",
    "        self.decoder_layers = nn.ModuleList([DecoderLayer(d_model, num_head, d_ff) for _ in range(N)])\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        \n",
    "        self.finalFc = nn.Linear(d_model, VOCAB_SIZE)  # Output layer to predict next token\n",
    "\n",
    "    def forward(self, dec_input, enc_output, paddingMask, lookaheadMask):\n",
    "        batch_size = dec_input.shape[0]\n",
    "        seq_len = dec_input.shape[1]\n",
    "        \n",
    "        pos = torch.arange(0, seq_len).unsqueeze(0).repeat(batch_size, 1)\n",
    "        \n",
    "        output = self.dropout(self.embedding(dec_input) + self.pos_embedding(pos))\n",
    "        \n",
    "        # lookaheadMask = makeMask(input, 'lookahead')\n",
    "        # paddingMask = makeMask(input, 'padding')\n",
    "\n",
    "        \n",
    "        for layer in self.decoder_layers:\n",
    "            output = layer(output, enc_output, paddingMask, lookaheadMask)\n",
    "            \n",
    "        logits = self.finalFc(output)\n",
    "            \n",
    "        return logits\n",
    "    \n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, N=6, d_model=512, num_head=8, d_ff=2048):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = Encoder(N, d_model, num_head, d_ff)\n",
    "        self.decoder = Decoder(N, d_model, num_head, d_ff)\n",
    "        \n",
    "        def forward(self, enc_input, dec_input):\n",
    "            # Encoder\n",
    "            enc_output = self.encoder(enc_input)\n",
    "            \n",
    "            # Decoder\n",
    "            logits, dec_output = self.decoder(dec_input, enc_output)\n",
    "            \n",
    "            return logits, dec_output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ab94006",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# if __name__ == \"__main__\":\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "VOCAB_SIZE = 10000\n",
    "SEQ_LEN = 60\n",
    "\n",
    "\n",
    "PAD_IDX = 0\n",
    "BOS_IDX = 2\n",
    "SOS_IDX = 3\n",
    "\n",
    "\n",
    "\n",
    "# ENV = 'COLAB'\n",
    "ENV = 'KAGGLE'\n",
    "# ENV = 'SYSTEM'\n",
    "\n",
    "# Option for Mixed Precision\n",
    "FP16 = True\n",
    "# FP16 = False\n",
    "\n",
    "N = 6\n",
    "D_MODEL = 256\n",
    "NUM_HEAD = 8 \n",
    "D_FF = 512\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 1e-4\n",
    "WEIGHT_DECAY = 0\n",
    "\n",
    "CONFIG = {\n",
    "    'VOCAB_SIZE': VOCAB_SIZE,\n",
    "    'SEQ_LEN': SEQ_LEN,\n",
    "    'N': N,\n",
    "    'D_MODEL': D_MODEL,\n",
    "    'NUM_HEAD': NUM_HEAD,\n",
    "    'D_FF': D_FF,\n",
    "    'BATCH_SIZE': BATCH_SIZE,\n",
    "    'WEIGHT_DECAY' : WEIGHT_DECAY,\n",
    "    'LEARNING_RATE' : LEARNING_RATE,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247a4458",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdnjsdlf325\u001b[0m (\u001b[33mdnjsdlf325-yeungnam-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "creating run (0.0s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "CommError",
     "evalue": "Error uploading run: returned error 403: {\"data\":{\"upsertBucket\":null},\"errors\":[{\"message\":\"permission denied\",\"path\":[\"upsertBucket\"],\"extensions\":{\"code\":\"PERMISSION_ERROR\"}}]}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCommError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 10\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# if want to run in offline mode\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# os.environ[\"WANDB_MODE\"] = \"dryrun\"\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# wandb.init(project=\"Transformer_bible\", entity=\"jiwon7258\")\u001b[39;00m\n\u001b[0;32m      9\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWANDB_MODE\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monline\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 10\u001b[0m \u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtransformer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mentity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdnjsdlf325\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mCONFIG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob_type\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m wandb\u001b[38;5;241m.\u001b[39mrun\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mVOCAB_SIZE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mSEQ_LEN\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mN\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mD_MODEL\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mD_FF\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     14\u001b[0m dataset \u001b[38;5;241m=\u001b[39m wandb\u001b[38;5;241m.\u001b[39mArtifact(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbible-dataset_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mVOCAB_SIZE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mSEQ_LEN\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\dnjsd\\anaconda3\\envs\\torch\\lib\\site-packages\\wandb\\sdk\\wandb_init.py:1620\u001b[0m, in \u001b[0;36minit\u001b[1;34m(entity, project, dir, id, name, notes, tags, config, config_exclude_keys, config_include_keys, allow_val_change, group, job_type, mode, force, anonymous, reinit, resume, resume_from, fork_from, save_code, tensorboard, sync_tensorboard, monitor_gym, settings)\u001b[0m\n\u001b[0;32m   1616\u001b[0m     wl\u001b[38;5;241m.\u001b[39m_get_logger()\u001b[38;5;241m.\u001b[39mexception(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror in wandb.init()\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39me)\n\u001b[0;32m   1618\u001b[0m \u001b[38;5;66;03m# Need to build delay into this sentry capture because our exit hooks\u001b[39;00m\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;66;03m# mess with sentry's ability to send out errors before the program ends.\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sentry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dnjsd\\anaconda3\\envs\\torch\\lib\\site-packages\\wandb\\analytics\\sentry.py:157\u001b[0m, in \u001b[0;36mSentry.reraise\u001b[1;34m(self, exc)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexception(exc)\n\u001b[0;32m    155\u001b[0m \u001b[38;5;66;03m# this will messily add this \"reraise\" function to the stack trace,\u001b[39;00m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;66;03m# but hopefully it's not too bad\u001b[39;00m\n\u001b[1;32m--> 157\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mwith_traceback(sys\u001b[38;5;241m.\u001b[39mexc_info()[\u001b[38;5;241m2\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\dnjsd\\anaconda3\\envs\\torch\\lib\\site-packages\\wandb\\sdk\\wandb_init.py:1606\u001b[0m, in \u001b[0;36minit\u001b[1;34m(entity, project, dir, id, name, notes, tags, config, config_exclude_keys, config_include_keys, allow_val_change, group, job_type, mode, force, anonymous, reinit, resume, resume_from, fork_from, save_code, tensorboard, sync_tensorboard, monitor_gym, settings)\u001b[0m\n\u001b[0;32m   1603\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_settings\u001b[38;5;241m.\u001b[39mx_server_side_derived_summary:\n\u001b[0;32m   1604\u001b[0m             init_telemetry\u001b[38;5;241m.\u001b[39mfeature\u001b[38;5;241m.\u001b[39mserver_side_derived_summary \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m-> 1606\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_settings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_printer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1608\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1609\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m wl:\n",
      "File \u001b[1;32mc:\\Users\\dnjsd\\anaconda3\\envs\\torch\\lib\\site-packages\\wandb\\sdk\\wandb_init.py:1018\u001b[0m, in \u001b[0;36m_WandbInit.init\u001b[1;34m(self, settings, config, run_printer)\u001b[0m\n\u001b[0;32m   1015\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m result\u001b[38;5;241m.\u001b[39mrun_result\n\u001b[0;32m   1017\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error \u001b[38;5;241m:=\u001b[39m ProtobufErrorHandler\u001b[38;5;241m.\u001b[39mto_exception(result\u001b[38;5;241m.\u001b[39mrun_result\u001b[38;5;241m.\u001b[39merror):\n\u001b[1;32m-> 1018\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\n\u001b[0;32m   1020\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result\u001b[38;5;241m.\u001b[39mrun_result\u001b[38;5;241m.\u001b[39mHasField(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m   1021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Error(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAssertion failed: run_result is missing the run field\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mCommError\u001b[0m: Error uploading run: returned error 403: {\"data\":{\"upsertBucket\":null},\"errors\":[{\"message\":\"permission denied\",\"path\":[\"upsertBucket\"],\"extensions\":{\"code\":\"PERMISSION_ERROR\"}}]}"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "import os\n",
    "# if want to run in offline mode\n",
    "\n",
    "# os.environ[\"WANDB_MODE\"] = \"dryrun\"\n",
    "# wandb.init(project=\"Transformer_bible\", entity=\"jiwon7258\")\n",
    "\n",
    "\n",
    "os.environ[\"WANDB_MODE\"] = \"online\"\n",
    "wandb.init(project=\"transformer\", entity=\"dnjsdlf325-yeungnam-university-org\", config = CONFIG, job_type = 'train')\n",
    "wandb.run.name = f\"train_{VOCAB_SIZE}_{SEQ_LEN}_{N}_{D_MODEL}_{D_FF}\"\n",
    "\n",
    "\n",
    "dataset = wandb.Artifact(f'bible-dataset_{VOCAB_SIZE}_{SEQ_LEN}', type='dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9291ea09",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = wandb.run.use_artifact(f'bible-dataset_{VOCAB_SIZE}_{SEQ_LEN}:latest')\n",
    "\n",
    "# Download the artifact's contents\n",
    "artifact_dir = dataset.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3fb97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# or Train / Valid Data\n",
    "src_train_path = os.path.join(artifact_dir,'src_train.pkl')\n",
    "src_valid_path = os.path.join(artifact_dir,'src_valid.pkl')\n",
    "trg_train_path = os.path.join(artifact_dir,'trg_train.pkl')\n",
    "trg_valid_path = os.path.join(artifact_dir,'trg_valid.pkl')\n",
    "\n",
    "src_train = joblib.load(src_train_path)\n",
    "src_valid = joblib.load(src_valid_path)\n",
    "trg_train = joblib.load(trg_train_path)\n",
    "trg_valid = joblib.load(trg_valid_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccd09af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, src_data, trg_data):\n",
    "        super().__init__()\n",
    "\n",
    "        assert len(src_data) == len(trg_data)\n",
    "\n",
    "        self.src_data = src_data\n",
    "        self.trg_data = trg_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.src_data)\n",
    "        \n",
    "    def __getitem__ (self, idx):\n",
    "        src = self.src_data[idx]\n",
    "        trg_input = self.trg_data[idx]\n",
    "        trg_output = trg_input[1:SEQ_LEN]\n",
    "        trg_output = np.pad(trg_output, (0,1), 'constant', constant_values =0)\n",
    "        # (seq_len,)\n",
    "        return torch.Tensor(src).long(), torch.Tensor(trg_input).long(), torch.Tensor(trg_output).long()\n",
    "\n",
    "train_dataset = TrainDataset(src_train, trg_train)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle= True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c1f1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValidDataset(Dataset):\n",
    "    def __init__(self, src_data, trg_data):\n",
    "        super().__init__()\n",
    "\n",
    "        assert len(src_data) == len(trg_data)\n",
    "\n",
    "        self.src_data = src_data\n",
    "        self.trg_data = trg_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.src_data)\n",
    "        \n",
    "    def __getitem__ (self, idx):\n",
    "        src = self.src_data[idx]\n",
    "        trg_input = self.trg_data[idx]\n",
    "        trg_output = trg_input[1:SEQ_LEN]\n",
    "        trg_output = np.pad(trg_output, (0,1), 'constant',constant_values= 0)\n",
    "\n",
    "        return torch.Tensor(src).long(), torch.Tensor(trg_input).long(), torch.Tensor(trg_output).long()\n",
    "\n",
    "valid_dataset = ValidDataset(src_valid, trg_valid)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle= False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5be1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer(N, HIDDEN_DIM, NUM_HEAD, INNER_DIM).to(device)\n",
    "ic.disable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e8ade2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "test1 = torch.randint(low = 0, high = 1000, size = (SEQ_LEN,))\n",
    "test2 = torch.randint(low = 0, high = 1000, size = (SEQ_LEN,))\n",
    "summary(model, [(SEQ_LEN,), (SEQ_LEN,)], dtypes = [torch.int, torch.int])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dadfbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.named_parameters():\n",
    "    if 'weight' in param[0] and 'layerNorm' not in param[0] :\n",
    "        torch.nn.init.xavier_uniform_(param[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4318e303",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params = model.parameters(), lr = LEARNING_RATE, weight_decay = WEIGHT_DECAY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40588f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def criterion(logits: torch.tensor, targets: torch.tensor):\n",
    "    return nn.CrossEntropyLoss(ignore_index=PAD_IDX)(logits.view(-1,VOCAB_SIZE), targets.view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183d0564",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch):\n",
    "    # train 모드로 변경\n",
    "    model.train()\n",
    "\n",
    "    # for the Mixed Precision\n",
    "    # Pytorch 예제 : https://pytorch.org/docs/stable/notes/amp_examples.html#amp-examples\n",
    "    if(FP16):\n",
    "        scaler = amp.GradScaler()\n",
    "\n",
    "    dataset_size = 0\n",
    "    running_loss = 0\n",
    "    running_accuracy = 0\n",
    "    accuracy = 0\n",
    "\n",
    "    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "\n",
    "    for step, (src, trg_input, trg_output) in bar:\n",
    "        src = src.to(device)\n",
    "        trg_input = trg_input.to(device)\n",
    "        trg_output = trg_output.to(device)\n",
    "\n",
    "        batch_size = src.shape[0]\n",
    "\n",
    "        if(FP16):\n",
    "            with amp.autocast(enabled=True):\n",
    "                logits, output = model(enc_src=src, dec_src=trg_input)\n",
    "                loss = criterion(logits, trg_output)\n",
    "\n",
    "                # loss를 Scale\n",
    "                # Scaled Grdients를 계산(call)하기 위해 scaled loss를 backward()\n",
    "                scaler.scale(loss).backward()\n",
    "                # scaler.step() first unscales the gradients of the optimizer's assigned params.\n",
    "                # If these gradients do not contain infs or NaNs, optimizer.step() is then called,\n",
    "                # otherwise, optimizer.step() is skipped.\n",
    "                scaler.step(optimizer)\n",
    "\n",
    "                # Updates the scale for next iteration.\n",
    "                scaler.update()\n",
    "\n",
    "        else:\n",
    "            logits, output = model(enc_src=src, dec_src=trg_input)\n",
    "            loss = criterion(logits, trg_output)\n",
    "\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "            optimizer.step()\n",
    "\n",
    "        # logits (bs, seq_len, VOCAB_SIZE)\n",
    "        # trg_output (bs, seq_len)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # change learning rate by Scheduler\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "        # loss.item()은 loss를 Python Float으로 반환\n",
    "        # loss.item()은 batch data의 average loss이므로, sum of loss를 구하기 위해 batch_size를 곱해준다\n",
    "        running_loss += loss.item() * batch_size\n",
    "        running_accuracy = np.mean(\n",
    "            output.view(-1).detach().cpu().numpy() == trg_output.view(-1).detach().cpu().numpy())\n",
    "\n",
    "        accuracy += running_accuracy\n",
    "\n",
    "        dataset_size += batch_size\n",
    "        epoch_loss = running_loss / dataset_size\n",
    "\n",
    "        bar.set_postfix(\n",
    "            Epoch=epoch, Train_Loss=epoch_loss, LR=optimizer.param_groups[0][\"lr\"], accuracy=accuracy / np.float(\n",
    "                step+1)\n",
    "        )\n",
    "\n",
    "        # break\n",
    "\n",
    "    accuracy /= len(dataloader)\n",
    "    # Garbage Collector\n",
    "    gc.collect()\n",
    "\n",
    "    return epoch_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756bdf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def valid_one_epoch(model, dataloader, device, epoch):\n",
    "    model.eval()\n",
    "\n",
    "    dataset_size = 0\n",
    "    running_loss = 0\n",
    "    accuracy = 0\n",
    "\n",
    "    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "\n",
    "    for step, (src, trg_input, trg_output) in bar:\n",
    "        src = src.to(device)\n",
    "        trg_input = trg_input.to(device)\n",
    "        trg_output = trg_output.to(device)\n",
    "\n",
    "        batch_size = src.shape[0]\n",
    "\n",
    "        logits, output = model(enc_src = src, dec_src = trg_input)\n",
    "        loss = criterion(logits, trg_output)\n",
    "\n",
    "        running_loss += loss.item() * batch_size\n",
    "        dataset_size += batch_size\n",
    "\n",
    "        # 실시간으로 정보를 표시하기 위한 epoch loss\n",
    "        val_loss = running_loss / dataset_size\n",
    "        running_accuracy = np.mean(output.view(-1).detach().cpu().numpy() == trg_output.view(-1).detach().cpu().numpy())\n",
    "        \n",
    "        accuracy += running_accuracy\n",
    "\n",
    "        bar.set_postfix(\n",
    "            Epoch=epoch, Valid_Loss=val_loss, LR=optimizer.param_groups[0][\"lr\"], accuracy = accuracy / np.float(step + 1)\n",
    "        )\n",
    "\n",
    "        # break\n",
    "\n",
    "    accuracy /= len(dataloader)\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    return val_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2d658d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(\n",
    "    model,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    device,\n",
    "    num_epochs,\n",
    "    metric_prefix=\"\",\n",
    "    file_prefix=\"\",\n",
    "    early_stopping=True,\n",
    "    early_stopping_step=10,\n",
    "):\n",
    "    # To automatically log graidents\n",
    "    wandb.watch(model, log_freq=100)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"[INFO] Using GPU:{}\\n\".format(torch.cuda.get_device_name()))\n",
    "\n",
    "    start = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = np.inf\n",
    "    history = defaultdict(list)\n",
    "    early_stop_counter = 0\n",
    "\n",
    "    # num_epochs만큼, train과 val을 실행한다\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        gc.collect()\n",
    "\n",
    "        train_epoch_loss, train_accuracy = train_one_epoch(\n",
    "            model,\n",
    "            optimizer,\n",
    "            scheduler,\n",
    "            dataloader= train_dataloader,\n",
    "            device=device,\n",
    "            epoch=epoch,\n",
    "        )\n",
    "\n",
    "        val_loss, val_accuracy = valid_one_epoch(\n",
    "            model, valid_dataloader, device=device, epoch=epoch\n",
    "        )\n",
    "\n",
    "        history[f\"{metric_prefix}Train Loss\"].append(train_epoch_loss)\n",
    "        history[f\"{metric_prefix}Train Accuracy\"].append(train_accuracy)\n",
    "        history[f\"{metric_prefix}Valid Loss\"].append(val_loss)\n",
    "        history[f\"{metric_prefix}Valid Accuracy\"].append(val_accuracy)\n",
    "\n",
    "\n",
    "        # Log the metrics\n",
    "        wandb.log(\n",
    "            {\n",
    "                f\"{metric_prefix}Train Loss\": train_epoch_loss,\n",
    "                f\"{metric_prefix}Valid Loss\": val_loss,\n",
    "                f\"{metric_prefix}Train Accuracy\" : train_accuracy,\n",
    "                f\"{metric_prefix}Valid Accuracy\" : val_accuracy,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        print(f\"Valid Loss : {val_loss}\")\n",
    "\n",
    "        # deep copy the model\n",
    "        if val_loss <= best_loss:\n",
    "            early_stop_counter = 0\n",
    "\n",
    "            print(\n",
    "                f\"Validation Loss improved( {best_loss} ---> {val_loss}  )\"\n",
    "            )\n",
    "\n",
    "            # Update Best Loss\n",
    "            best_loss = val_loss\n",
    "            \n",
    "            # Update Best Model Weight\n",
    "            # run.summary['Best RMSE'] = best_loss\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "            PATH = \"{}epoch{:.0f}_Loss{:.4f}.bin\".format(file_prefix, epoch, best_loss)\n",
    "            torch.save(model.state_dict(), PATH)\n",
    "            torch.save(model.state_dict(), f\"{file_prefix}best_{epoch}epoch.bin\")\n",
    "            # Save a model file from the current directory\n",
    "            wandb.save(PATH)\n",
    "\n",
    "            print(f\"Model Saved\")\n",
    "\n",
    "        elif early_stopping:\n",
    "            early_stop_counter += 1\n",
    "            if early_stop_counter > early_stopping_step:\n",
    "                break\n",
    "        \n",
    "        # break\n",
    "\n",
    "\n",
    "    end = time.time()\n",
    "    time_elapsed = end - start\n",
    "    print(\n",
    "        \"Training complete in {:.0f}h {:.0f}m {:.0f}s\".format(\n",
    "            time_elapsed // 3600,\n",
    "            (time_elapsed % 3600) // 60,\n",
    "            (time_elapsed % 3600) % 60,\n",
    "        )\n",
    "    )\n",
    "    print(\"Best Loss: {:.4f}\".format(best_loss))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925c2abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_training(\n",
    "    model = model,\n",
    "    optimizer = optimizer,\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer=optimizer, T_max=100, eta_min=1e-5),\n",
    "    device = device,\n",
    "    num_epochs = 2000,\n",
    "    metric_prefix=\"\",\n",
    "    file_prefix=\"\",\n",
    "    early_stopping=True,\n",
    "    early_stopping_step=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a6a80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'final.bin')\n",
    "wandb.save('final.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd64ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
